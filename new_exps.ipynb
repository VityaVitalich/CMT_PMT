{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import statsmodels.api as sm\n",
    "from copy import deepcopy\n",
    "\n",
    "import Utils\n",
    "import models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Cleaned_data.xlsx')\n",
    "df1 = pd.read_excel('PMT_N+2SD+3SD.xlsx', sheet_name='N-2SD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_perf = df1.filter(regex = 'Overperformers')\n",
    "over_perf['log'] = df1['LOG']\n",
    "#over_perf = over_perf.drop(columns=['Overperformers on levels 1 and 2', 'Overperformers on levels 2 and 3'])\n",
    "over_perf = over_perf.fillna(0).loc[:342]\n",
    "df = df.merge(over_perf, on='log', how='left')\n",
    "\n",
    "\n",
    "df = df.drop(columns=['log'])\n",
    "df['gender'] = pd.factorize(df['gender'])[0]\n",
    "\n",
    "\n",
    "df.columns = ['age', 'gender', 'ACC_ADD1', 'ACC_ADD2', 'ACC_ADD3', 'ACC_DIV1', 'ACC_DIV2', 'ACC_DIV3', 'ACC_MUL1',\n",
    "       'ACC_MUL2', 'ACC_MUL3', 'ACC_SUB1', 'ACC_SUB2', 'ACC_SUB3', 'RT_ADD1', 'RT_ADD2', 'RT_ADD3',\n",
    "       'RT_DIV1', 'RT_DIV2', 'RT_DIV3', 'RT_MUL1', 'RT_MUL2', 'RT_MUL3',\n",
    "       'RT_SUB1', 'RT_SUB2', 'RT_SUB3', 'ADD1', 'ADD2', 'ADD3', 'DIV1',\n",
    "       'DIV2', 'DIV3', 'MUL1', 'MUL2', 'MUL3', 'SUB1', 'SUB2',\n",
    "       'SUB3', 'm_score_bal', 'acc_1_bal', 'acc_2_bal', 'acc_3_bal',\n",
    "       'acc_4_bal', 'acc_5_bal', 'acc_6_bal', 'rt_1_bal', 'rt_2_bal',\n",
    "       'rt_3_bal', 'rt_4_bal', 'rt_5_bal', 'rt_6_bal', 'm_score_cl',\n",
    "       'acc_1_cl', 'acc_2_cl', 'acc_3_cl', 'acc_4_cl', 'acc_5_cl', 'acc_6_cl',\n",
    "       'rt_1_cl', 'rt_2_cl', 'rt_3_cl', 'rt_4_cl', 'rt_5_cl', 'rt_6_cl',\n",
    "       'n_sum', 'rt_mean', 'rt_cmt_mean', 'rt_bal', 'rt_cl', 'O_12', 'O_23', 'O_ADD', 'O_DIV','O_MUL', 'O_SUB']\n",
    "\n",
    "\n",
    "df['O_12'][(df['O_12'] == ' 1+2')] = 1\n",
    "df['O_12'] = df['O_12'].astype(int)\n",
    "df['O_23'][(df['O_23'] == ' 2+3')] = 1\n",
    "df['O_23'] = df['O_23'].astype(int)\n",
    "\n",
    "\n",
    "seed = 0xAB0BA\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['1', '2', '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = {}\n",
    "for target in targets:\n",
    "    valid_columns = []\n",
    "    target_col = pd.Series(np.zeros(len(df)))\n",
    "    for column in df.columns:\n",
    "        if ('ACC' in column) and (target in column):\n",
    "            target_col += df[column]\n",
    "        else:\n",
    "            valid_columns.append(column)\n",
    "    df_list[target] = (df[valid_columns], target_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.16it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for name in tqdm(targets):\n",
    "    X, y = df_list[name]\n",
    "    \n",
    "    res = models.LinRegStatmodels(X, y)\n",
    "    \n",
    "    r2 = res.rsquared\n",
    "    params = res.params.index\n",
    "    \n",
    "    results[name] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.659</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   45.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 29 Nov 2023</td> <th>  Prob (F-statistic):</th> <td>2.33e-44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:36:44</td>     <th>  Log-Likelihood:    </th> <td> -190.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   220</td>      <th>  AIC:               </th> <td>   400.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   210</td>      <th>  BIC:               </th> <td>   434.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>    3.0184</td> <td>    0.456</td> <td>    6.619</td> <td> 0.000</td> <td>    2.119</td> <td>    3.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACC_ADD1</th> <td>   -2.9255</td> <td>    0.552</td> <td>   -5.300</td> <td> 0.000</td> <td>   -4.014</td> <td>   -1.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACC_ADD2</th> <td>    0.7910</td> <td>    0.314</td> <td>    2.522</td> <td> 0.012</td> <td>    0.173</td> <td>    1.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACC_DIV1</th> <td>   -1.0434</td> <td>    0.374</td> <td>   -2.789</td> <td> 0.006</td> <td>   -1.781</td> <td>   -0.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACC_DIV2</th> <td>    1.0956</td> <td>    0.204</td> <td>    5.369</td> <td> 0.000</td> <td>    0.693</td> <td>    1.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACC_MUL2</th> <td>    1.1735</td> <td>    0.243</td> <td>    4.834</td> <td> 0.000</td> <td>    0.695</td> <td>    1.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACC_SUB2</th> <td>    0.8538</td> <td>    0.259</td> <td>    3.295</td> <td> 0.001</td> <td>    0.343</td> <td>    1.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RT_ADD1</th>  <td>    0.2322</td> <td>    0.037</td> <td>    6.322</td> <td> 0.000</td> <td>    0.160</td> <td>    0.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RT_ADD3</th>  <td>   -0.0829</td> <td>    0.013</td> <td>   -6.254</td> <td> 0.000</td> <td>   -0.109</td> <td>   -0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RT_SUB3</th>  <td>    0.0536</td> <td>    0.012</td> <td>    4.580</td> <td> 0.000</td> <td>    0.031</td> <td>    0.077</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.189</td> <th>  Durbin-Watson:     </th> <td>   1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.552</td> <th>  Jarque-Bera (JB):  </th> <td>   0.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.099</td> <th>  Prob(JB):          </th> <td>   0.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.234</td> <th>  Cond. No.          </th> <td>    228.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.659\n",
       "Model:                            OLS   Adj. R-squared:                  0.644\n",
       "Method:                 Least Squares   F-statistic:                     45.07\n",
       "Date:                Wed, 29 Nov 2023   Prob (F-statistic):           2.33e-44\n",
       "Time:                        00:36:44   Log-Likelihood:                -190.16\n",
       "No. Observations:                 220   AIC:                             400.3\n",
       "Df Residuals:                     210   BIC:                             434.3\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          3.0184      0.456      6.619      0.000       2.119       3.917\n",
       "ACC_ADD1      -2.9255      0.552     -5.300      0.000      -4.014      -1.837\n",
       "ACC_ADD2       0.7910      0.314      2.522      0.012       0.173       1.409\n",
       "ACC_DIV1      -1.0434      0.374     -2.789      0.006      -1.781      -0.306\n",
       "ACC_DIV2       1.0956      0.204      5.369      0.000       0.693       1.498\n",
       "ACC_MUL2       1.1735      0.243      4.834      0.000       0.695       1.652\n",
       "ACC_SUB2       0.8538      0.259      3.295      0.001       0.343       1.365\n",
       "RT_ADD1        0.2322      0.037      6.322      0.000       0.160       0.305\n",
       "RT_ADD3       -0.0829      0.013     -6.254      0.000      -0.109      -0.057\n",
       "RT_SUB3        0.0536      0.012      4.580      0.000       0.031       0.077\n",
       "==============================================================================\n",
       "Omnibus:                        1.189   Durbin-Watson:                   1.973\n",
       "Prob(Omnibus):                  0.552   Jarque-Bera (JB):                0.862\n",
       "Skew:                           0.099   Prob(JB):                        0.650\n",
       "Kurtosis:                       3.234   Cond. No.                         228.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['3'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_frequency = {}\n",
    "for name in df.columns:\n",
    "    params_frequency[name] = set()\n",
    "\n",
    "params_frequency['const'] = set()\n",
    "\n",
    "for res in results:\n",
    "    for param_name in results[res].params.index:\n",
    "        params_frequency[param_name].add(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': set(),\n",
       " 'gender': {'2'},\n",
       " 'ACC_ADD1': {'2', '3'},\n",
       " 'ACC_ADD2': {'1', '3'},\n",
       " 'ACC_ADD3': {'1', '2'},\n",
       " 'ACC_DIV1': {'2', '3'},\n",
       " 'ACC_DIV2': {'1', '3'},\n",
       " 'ACC_DIV3': {'1', '2'},\n",
       " 'ACC_MUL1': {'2'},\n",
       " 'ACC_MUL2': {'1', '3'},\n",
       " 'ACC_MUL3': {'1', '2'},\n",
       " 'ACC_SUB1': {'2'},\n",
       " 'ACC_SUB2': {'1', '3'},\n",
       " 'ACC_SUB3': {'2'},\n",
       " 'RT_ADD1': {'2', '3'},\n",
       " 'RT_ADD2': set(),\n",
       " 'RT_ADD3': {'2', '3'},\n",
       " 'RT_DIV1': set(),\n",
       " 'RT_DIV2': set(),\n",
       " 'RT_DIV3': set(),\n",
       " 'RT_MUL1': set(),\n",
       " 'RT_MUL2': {'1'},\n",
       " 'RT_MUL3': set(),\n",
       " 'RT_SUB1': set(),\n",
       " 'RT_SUB2': set(),\n",
       " 'RT_SUB3': {'3'},\n",
       " 'ADD1': set(),\n",
       " 'ADD2': set(),\n",
       " 'ADD3': set(),\n",
       " 'DIV1': {'1'},\n",
       " 'DIV2': set(),\n",
       " 'DIV3': set(),\n",
       " 'MUL1': set(),\n",
       " 'MUL2': {'1'},\n",
       " 'MUL3': set(),\n",
       " 'SUB1': set(),\n",
       " 'SUB2': set(),\n",
       " 'SUB3': {'2'},\n",
       " 'm_score_bal': set(),\n",
       " 'acc_1_bal': set(),\n",
       " 'acc_2_bal': set(),\n",
       " 'acc_3_bal': set(),\n",
       " 'acc_4_bal': set(),\n",
       " 'acc_5_bal': set(),\n",
       " 'acc_6_bal': set(),\n",
       " 'rt_1_bal': set(),\n",
       " 'rt_2_bal': set(),\n",
       " 'rt_3_bal': set(),\n",
       " 'rt_4_bal': set(),\n",
       " 'rt_5_bal': set(),\n",
       " 'rt_6_bal': set(),\n",
       " 'm_score_cl': set(),\n",
       " 'acc_1_cl': set(),\n",
       " 'acc_2_cl': set(),\n",
       " 'acc_3_cl': set(),\n",
       " 'acc_4_cl': set(),\n",
       " 'acc_5_cl': set(),\n",
       " 'acc_6_cl': set(),\n",
       " 'rt_1_cl': set(),\n",
       " 'rt_2_cl': set(),\n",
       " 'rt_3_cl': set(),\n",
       " 'rt_4_cl': set(),\n",
       " 'rt_5_cl': set(),\n",
       " 'rt_6_cl': set(),\n",
       " 'n_sum': set(),\n",
       " 'rt_mean': set(),\n",
       " 'rt_cmt_mean': set(),\n",
       " 'rt_bal': set(),\n",
       " 'rt_cl': set(),\n",
       " 'O_12': set(),\n",
       " 'O_23': set(),\n",
       " 'O_ADD': set(),\n",
       " 'O_DIV': set(),\n",
       " 'O_MUL': set(),\n",
       " 'O_SUB': set(),\n",
       " 'const': {'1', '2', '3'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name in params_frequency:\n",
    "    new_input = str(params_frequency[name])\n",
    "    if new_input == 'set()':\n",
    "        new_input = ''\n",
    "    params_frequency[name] = new_input\n",
    "\n",
    "with open(\"params_in_models_new.json\", \"w\") as outfile:\n",
    "    json.dump(params_frequency, outfile, indent=4)\n",
    "\n",
    "\n",
    "r2_dict = {}\n",
    "for name in results:\n",
    "    r2_dict[name] = results[name].rsquared\n",
    "\n",
    "with open(\"r2_LinReg_new.json\", \"w\") as outfile:\n",
    "    json.dump(r2_dict, outfile, indent=4)\n",
    "\n",
    "\n",
    "rmse_dict = {}\n",
    "for name in results:\n",
    "    rmse_dict[name] = float(np.sqrt(results[name].mse_total))\n",
    "\n",
    "with open(\"rmse_LinReg_new.json\", \"w\") as outfile:\n",
    "    json.dump(rmse_dict, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:29<00:00,  9.71s/it]\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for name in tqdm(targets):\n",
    "    X, y = df_list[name]\n",
    "\n",
    "    op, rmse, model = models.XGBReg(X, y)\n",
    "\n",
    "    result[name] = (op, rmse, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 2, 0.3, 0.6),\n",
       " 0.6458828026619117,\n",
       " XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.6, eta=0.3, gamma=0,\n",
       "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dic_xgb = {}\n",
    "opt_params = {}\n",
    "for elem in result:\n",
    "    rmse_dic_xgb[elem] = result[elem][1]\n",
    "    opt_params[elem] = result[elem][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rmse_XGB_new.json\", \"w\") as outfile:\n",
    "    json.dump(rmse_dic_xgb, outfile, indent=4)\n",
    "with open(\"params_XGB_new.json\", \"w\") as outfile:\n",
    "    json.dump(opt_params, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for name in tqdm(targets):\n",
    "    X, y = df_list[name]\n",
    "\n",
    "    op, rmse, model = models.RFReg(X, y)\n",
    "\n",
    "    result[name] = (op, rmse, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dic_rf = {}\n",
    "opt_params = {}\n",
    "for elem in result:\n",
    "    rmse_dic_rf[elem] = result[elem][1]\n",
    "    opt_params[elem] = result[elem][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rmse_RF_new.json\", \"w\") as outfile:\n",
    "    json.dump(rmse_dic_rf, outfile, indent=4)\n",
    "\n",
    "with open(\"params_RF_new.json\", \"w\") as outfile:\n",
    "    json.dump(opt_params, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rmse_RF_new.json') as file:\n",
    "    res_rf = json.load(file)\n",
    "with open('params_RF_new.json') as file:\n",
    "    params_rf = json.load(file)\n",
    "\n",
    "with open('rmse_XGB_new.json') as file:\n",
    "    res_gb = json.load(file)\n",
    "\n",
    "with open('params_XGB_new.json') as file:\n",
    "    params_gb = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0.27264622347353584, '2': 0.4232025548675165, '3': 0.6024865819197409}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "opt_models = {}\n",
    "for elem in tqdm(res_rf):\n",
    "    diff = res_rf[elem] - res_gb[elem]\n",
    "    if diff > 0:\n",
    "        opt_params = params_gb[elem]\n",
    "        model = XGBRegressor(n_estimators = opt_params[0], max_depth=opt_params[1], eta=opt_params[2], colsample_bytree=opt_params[3])\n",
    "    else:\n",
    "        opt_params = params_rf[elem]\n",
    "        model = RandomForestRegressor(n_estimators=opt_params[0], max_depth=opt_params[1], min_samples_leaf=opt_params[2], min_samples_split=opt_params[3], n_jobs=-1)\n",
    "\n",
    "    X,y = df_list[elem]\n",
    "    model.fit(X,y)\n",
    "\n",
    "    opt_models[elem] = model  \n",
    "\n",
    "\n",
    "FI5 = {}\n",
    "for elem in opt_models:\n",
    "    if isinstance(opt_models[elem], XGBRegressor):\n",
    "        FI = list(zip(opt_models[elem].feature_importances_, opt_models[elem].get_booster().feature_names))\n",
    "        FI5[elem] = ([(elem[1], float(elem[0])) for elem in sorted(FI, key = lambda x: x[0], reverse=True)[:5]], 'GB')\n",
    "    else:\n",
    "        X,y = df_list[elem]\n",
    "        FI = list(zip(opt_models[elem].feature_importances_, X.columns))\n",
    "        FI5[elem] = ([(elem[1], float(elem[0])) for elem in sorted(FI, key = lambda x: x[0], reverse=True)[:5]], 'RF')\n",
    "\n",
    "    \n",
    "# with open('FeatureImportance.json', 'w') as file:\n",
    "#     json.dump(FI5, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FeatureImportance5_new.json', 'w') as file:\n",
    "     json.dump(FI5, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
